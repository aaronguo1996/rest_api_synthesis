#+title: apiphany re (rust reimpl) todo

* bench results
reminders:
- remember to pass =--release= to =maturin=!
- can use =--cache= to get cached sols for bench script
** preliminary
*** 3.1
**** limit 6, 1 worker
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= |  6 |
| parallel             | no |
| workers              |  1 |
| repeat               |  1 |

results (measured in ms):
| bench                         |  py2rs | interpret |  total |
|-------------------------------+--------+-----------+--------|
| python w/ entries opt (div 5) |  0.000 |    17.448 | 17.448 |
| rust w/ entries opt           | 21.390 |    20.335 | 56.195 |
| rust w/ stack machine         | 20.224 |    15.677 | 38.526 |
**** limit 10, parallel
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= |  10 |
| parallel             | yes |
| workers              |   6 |
| repeat               |   5 |

results (measured in ms):
| bench                      |  py2rs | interpret |    total |
|----------------------------+--------+-----------+----------|
| python w/ entries opt      |  0.000 |  1616.859 | 1616.859 |
| rust w/ stack machine      | 76.656 |   167.860 |  255.582 |
| rust w/ nested parallelism | 81.590 |   156.659 |  249.801 |
| rust w/ jemalloc           | 81.148 |    53.768 |  151.104 |
*** 1.4
**** limit 6, 1 worker
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= |  6 |
| parallel             | no |
| workers              |  1 |
| repeat               |  1 |

results (measured in ms):
| bench                         |   py2rs | interpret |   total |
|-------------------------------+---------+-----------+---------|
| python w/ entries opt (div 5) |   0.000 |   975.245 | 975.245 |
| rust w/ entries opt           | 146.884 |   356.660 | 519.508 |
**** limit 7, 1 worker
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= |  7 |
| parallel             | no |
| workers              |  1 |
| repeat               |  1 |

results (measured in s):
| bench                         | py2rs | interpret | total |
|-------------------------------+-------+-----------+-------|
| python w/ entries opt (div 5) | 0.000 |     4.958 | 4.958 |
| rust w/ entries opt           | 0.244 |     1.057 | 1.332 |
**** limit 10, 1 worker
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= | 10 |
| parallel             | no |
| workers              |  1 |
| repeat               |  1 |

results (measured in s):
| bench                         | py2rs | interpret |  total |
|-------------------------------+-------+-----------+--------|
| python w/ entries opt (div 5) | 0.000 |    64.426 | 64.426 |
| rust w/ entries opt           | 0.586 |     2.355 |  3.084 |
| rust w/ stack machine         | 0.588 |     2.203 |  2.922 |
**** limit 10, parallel
synthesis settings:
| =DEFAULT_LENGTH_LIMIT= |  10 |
| parallel             | yes |
| workers              |   6 |
| repeat               |   5 |

(both have repeats!)

results (measured in s):
| bench                              | py2rs | interpret |  total |
|------------------------------------+-------+-----------+--------|
| python w/ entries opt              | 0.000 |    99.413 | 99.413 |
| rust w/ stack machine              | 0.557 |     2.628 |  3.322 |
| rust w/ nested parallelism         | 0.553 |     2.630 |  3.313 |
| rust w/ minispur                   | 0.567 |     2.563 |  3.266 |
| rust w/ jemalloc                   | 0.578 |     1.014 |  1.733 |
| rust w/ bugfixes (simple choice)   | 0.578 |     3.300 |  4.000 |
| rust w/ bugfixes (weighted choice) | 0.547 |     9.086 |  9.794 |
* TODO remaining correctness bugs
** TODO get input selection on par with py impl
should improve rankings
** TODO situations where there are no input values for an input name?
e.g. 2.3
** TODO evaluation gets stuck in a loop i think
2.11, 2.12
* DONE fix perf bugs
CLOSED: [2021-06-27 Sun 18:35]
** DONE larger objects cause perf, not weighted random algo
CLOSED: [2021-06-25 Fri 13:40]
** DONE memory alloc?
CLOSED: [2021-06-27 Sun 18:35]
improving the allocator used seems to have a very large impact on performance:
- system to jemalloc improved by 2.5x
- jemalloc to mimalloc improved by 1.4x
thus, it stands to reason that a lot of perf could be gained by minimizing the number of allocations we're doing.

in particular, we do have a lot of those "clone" calls in execution, even though in most circumstances we don't need to allocate our own =Value=. =Proj= can just return a reference into an existing =Value=, owned by the

I want a =Cow<'a, BorrowedValue<'a>>= - where =BorrowedValue= is the borrowed value type from simdjson?

We could also do Slab allocation: store all =Value= allocations on a pre-allocated =Slab= in the =Arena= instead of having owned =Values= floating around everywhere, and just store references/keys into this =Slab=. (see =slab= crate and their keys - stack becomes just a stack of keys!)

Even for Vector operations (i.e. bind) - we can just store a vector to =Cow<'a, Value>=!

also: use Bumpalo arena allocation for even faster?
** TODO profiling
* DONE get it working lol - test baseline perf!
CLOSED: [2021-06-20 Sun 15:30]
fast RE example - 3.1. slow RE example - 1.4
* DONE low-hanging fruit: rust command-line args
CLOSED: [2021-06-20 Sun 15:45]
https://deterministic.space/high-performance-rust.html
doesn't seem to do much lol
* DONE simplify programs before translation
CLOSED: [2021-06-20 Sun 15:30]
make sure all programs are simplified
* DONE structure of entries?
CLOSED: [2021-06-20 Sun 22:14]
see new =DynamicAnalyzer.get_trace= code
=entries= in the code is an indexed version of the parsed entries, built by =index_entries=, in which entries are transformed from a =[TraceEntry]= to a =HashMap<endpoint + method, HashMap<arg_names, (HashMap<arg_name, arg_value>, response, weight)>>= - this is presumably for performance purposes, added in the recent fix-benchmarks stuff
we may want to use this instead of our own SoA stuff, since it's probably more performant tbfh (i.e. we're no longer doing multiple =O(n)= passes over the traces to find matching ones)

we don't care about granularity level though (or at least right now we don't), so we can do even better: =HashMap<(endpoint, method, arg_names, arg_values), Response=. This would only require one access instead of 4! but we'd have to implement some more preprocessing stuff

soa stuff prolly won't be necessary tbh.
** TODO small optimizations on top of new traces structure
- [X] spur
- [ ] smallvec
* DONE implement stack machine-based interpreter
CLOSED: [2021-06-21 Mon 12:47]
right now, when executing, we basically use this AST walker lookin thing. it's okay, but it seems pretty unperformant. instead, we should translate our Expressions, we should translate them into what are basically stack VM operations which will be much more simple to evaluate. instead of keeping track of an instruction pointer into program expressions along with dealing with nested recursive function calls and all that, each =ExecEnv= will just have a single instruction pointer. it starts at the beginning of the program, and stops at either an error (returning =None=) or when it sees a =Return= instruction (returns the value and cost). This will need changes to a few parts of the system atm:
** the state ExecEnv needs to store
=ExecEnv= should have two stacks: a =data= stack with =Value= values on it, and a =call= stack which will be explained below.
=ExecEnv= should also keep track of cost as we go along.
And finally, =ExecEnv= should have a few "registers" which will also be explained below:
- =tip=: the index of the top of the branch after the last successful loop iteration.
** how expressions themselves are translated
expressions should be translated as follows:
- =VarExpr(v)= becomes =Var(v)=. Reads =v= from env and pushes it to stack.
- =Proj(v, f)= becomes =Proj(f)=. Pops =v= off stack and projects =f= into it. Pushes result back onto stack.
- =App(e, args)= becomes =Arg(name)= and =App(n)=. =Arg(name)= pushes an argument name to the stack. =App(n)= pops off the last =n * 2= values: the last =n= values are used as the argument names, while the next =n= values are used as the argument values.
- =Filter(o, f, v)= becomes =Filter(f)=. Pops =o= and =v= off the stack. Projects =f= into =o=, then errors out if value isn't equal to =v=.
  - Can be broken down into =Proj(o, f)= and =Guard(v)=; =Guard(v)= pops item off stack and errors out if not equal.
- =Assign(x, v, false)= becomes =Assign(x)=. Pops =v= off stack, assigns it to =x= in env.
- =Assign(x, v, true)= becomes =Bind(x)=. =Bind(x)= first pops =v= off the stack. If =x= is empty, error out. Otherwise, add a tuple with four values to the top of the call stack: the index of =x= on the stack, the ip of the next instruction, 0 (the starting loop index), and the length of the list. It also sets =tip= to the current top of the stack.
- =Ret= is a new instruction that indicates the end of a program. Its behavior changes depending on the contents of the call stack.
  - If the call stack is empty, pop the top value off the stack and return it along with the cost.
  - If the call stack is not empty:
    - Peek at the top of the call stack and increment the third element of the tuple.
    - If the third and fourth elements are not equal, jump back to the ip value given by the second element of the tuple. Set =tip= to the index of the current top of the stack.
    - Otherwise, if the third and fourth elements are equal, we've reached the end of the list. Pop the tuple off the call stack. Pop all elements from the top element of the stack until 1 plus the first element of the tuple (which denotes the stack index of the og list), inserting them into a new array =v=. Then pop the og list off the stack and push =v= to the stack.
      - If =v= is empty, don't bother pushing it to the stack and error out.
      - Otherwise, check the call stack again to see if it's empty (i.e. repeat the logic of =Ret=)
      - In either case, set =tip= to the index of the current top of the stack
*** error behavior
If the stack machine needs to "error out," just pretend like you hit a =Ret= instruction, with the following caveats:

- If the call stack is empty, give up now and return =None=
- Otherwise, do the call stack jumping stuff as dictated by =Ret= semantics above, unsetting the error flag while also removing everything on the stack up until (but not including =tip=)

implementation wise, we can just have an =error= boolean flag on =ExecEnv=, make "erroring out" just jumping to the =Ret= instruction and setting the flag (we know where the =Ret= instr is since we know how long the program is - we don't store subprograms, so the start of the next program - 1 is our =Ret=.). Then in the impl for =Ret=, just have it do diff things if the =error= flag is set.
** create a new state struct for instruction translation
Instead of having disparate functions =translate_expr=, =translate_prog=, etc., they should all be methods of a struct in charge of translation that keeps state: =Compiler= or something. since we now need to be able to keep track of state to have instructions reference other instructions added after itself, we can use the =Compiler= struct to store this state.
* DONE add scores to stack machine
CLOSED: [2021-06-24 Thu 17:26]
* DONE verify correctness
CLOSED: [2021-06-24 Thu 17:26]
* DONE add =filter_num= stuff
CLOSED: [2021-06-27 Sun 18:35]
run repeats to get rank, run =filter_nums= to get multiple ranks
* DONE finish complete re pipeline - hook up into rest of program
CLOSED: [2021-06-27 Sun 18:35]
* TODO traces structure - move value vec to left side
this removes the last linear search and means getting traces is just get in a hashmap.
this requires rolling our own hash impl for Value. we can do that p easy.
or just call =value.as_str()= and hash that lmao
* TODO additional stack machine opts
** TODO remove need for "env"? during translation, compile env access into stack access
basically, we know at "compile-time" how many pushes and pops we're gonna have at every point. so during compile-time, instead of having a heap var, just have an offset from the top of the stack.

#+begin_example
stack starts at 0
Assume there exists one value on the stack: [x]

                 the stack is knowable at compile-/translate-time!
Assign("x")      Treat this as a dup; x at stack positions 0 and 1
Proj(".a.b.c")   stack: [x x.a.b.c]
Assign("y")      stack: [x x.a.b.c x.a.b.c]
..
..
..
..               stack: [x x.a.b.c x.a.b.c .. ..] (assume two more items pushed)
Var("y")         at compile-time, we know og y at stack offset -3 (ix of top elem - 3). So this can just be Dup(-3)
                 stack: [x x.a.b.c x.a.b.c .. .. x.a.b.c]
Var("x")         at compile-time, we know og x at stack offset -6 (ix of top elem - 6). So this can just be Dup(-6)
                 stack: [x x.a.b.c x.a.b.c .. .. x.a.b.c x]
#+end_example

Trade-off: more time to compile and translate, less to interpret. I say it's a win!
This also makes things more JITable; amenable to lower-level vm
*** alternatively: compile to no-assign form
strictly speaking, assigns aren't necessary. we can just subst and simplify them away.
so in our evaluator, we can just only evaluate simplified programs with no vars
jk this is the same thing as above lol
** TODO simplify to just one stack?
** TODO even lower-level vm?
- something cranelift-jitable even
  - lots of Bit Twiddling
- represent json as raw bytes - don't use the enum and all this indirection
- env stuff? extern rust fns?
  - https://github.com/bytecodealliance/cranelift/issues/675
  - https://github.com/bytecodealliance/cranelift/issues/860
*** TODO look at jq for inspiration
=compile.c/h=, =opcode_list.h=, =exec_stack.h=, =execute.c=
=exec_stack.h= for memory model

execute.c greps of interest:
=LOADK= - loading constants (jv - json value - arrays)
object - dealing with objets
=jq_get_attr= - gettin attribute from jv. filter??
=jv.h/c= - [j]son [v]alue representation

in jv.h:
all json objects are represented by struct =jv=.
their "kind" determines if they're array, number, string, etc.

in jv.c:
=jvp_object_new= - creates a new object. how does this work?
#+begin_src c
struct object_slot {
  int next; /* next slot with same hash, for collisions */
  uint32_t hash;
  jv string;
  jv value;
};

typedef struct {
  jv_refcnt refcnt;
  int next_free;
  struct object_slot elements[];
} jvp_object;
#+end_src
basically, =jvp_object= just stores a list of =object_slots=, which is a map from string to value. surprise!
* DONE try using smallvec for traces?
CLOSED: [2021-06-26 Sat 18:13]
* DONE parallelism with rayon
CLOSED: [2021-06-27 Sun 18:35]
