#+title: apiphany re (rust reimpl) todo

right now, the structure of RE is like this:

- Each type of =Expression= is represented as a subclass of =Expression= - memory allocation is all over the place lol
- during program execution, the only time we modify env is pushing/popping vars. the only other time we even look at analyzer state is to get traces.

in =DynamicAnalyzer.get_trace=, the code loops through the traces multiple times, progressively filtering down traces which match progressively tighter abstraction levels, up to the desired abstraction level. idk if this is performant? or maybe it'll be even more performant for us with our soa approach.

Ideas for us that we can use:

- Represent an =Expression= as an Enum instead of a bunch of subclasses of a root class - in this way,
  - Additionally, when we are parsing expressions, we should allocate all of our expressions into a single arena vector, where the children are allocated before the current expression. (Recursive calls etc)
  - This would allow us to be v cache efficient with exprs!
  - Alternatively: don't even bother with translating, just execute directly (from Python classes?)
- Instead of =DynamicAnalysis=, we now have a struct for an execution context which holds the environment and all that
  - Execution takes one input and one expr
  - We'll have an execution runner responsible for coordinating running between everything - this would also handle multithreaded/tiled runs and all that
  - Execution runner should hold Vec/Slab with exprs and traces
    - or references to those things
    - some root struct translates everything, responsible for running everything
- Multithreaded execution - we have a bunch of programs. We have a bunch of inputs we want to check against outputs. This should be TRIVIALLY parallelizable.
  - Prolly would be aided with tiling, so we don't thrash the cache badly
  - This indicates that translating Python classes to Rust =Expr= enums, stored in a cache-friendly way in one =Vec=, might be good for performance - if we're repeatedly interpreting a program, might be good to keep the program in cache and keep mem use down.
  - Might want to pad expr things to 64 bytes to avoid false sharing?
    - But we're not writing to exprs, just reading. So it shouldn't matter lol

Future things:
- Bytecode/JIT compilation, if this is still too slow

concrete actions:
- [X] finish data structure stuff
  - incl minimal subset of datatypes needed for RE
    - need less info than for synthesis, which uses LogAnalyzer
    - we use DynamicAnalyzer
  - [X] expr
  - [X] program - list of expr!
  - [X] trace
- [X] finish translation logic
  - [X] expr
  - [X] trace
    - we don't even need to translate this?
    - just read straight from file - reimplement =parse_entries=
      - [ ] reimpl =analyzer/parser.py=?
        could just use a har parser (e.g. =har-rs=, etc.)
      - parse minimal subset of har/TraceEntry needed for RE
        - see above
  - [X] program
- [-] impl re algorithm
  - [X] start with simple tree walker
    - impl bind: iterator map!
  - [ ] proceed to stack machine with code and data stacks
    - which would be more amenable to parallelism?
    - but we're alr doin parallelism on a program execution level

*extra parallelism*:
when evaluating after binding assigns, we can ||ize!

*improvement for expr*:
have a stack machine as our executor! executing instuctions which modify a stack and a persistent environment
Var(v): get v from env and push v.
App(f, n): pop n vars. push f(n) - vector result?
- Named args?
  - for each arg, pop off stack, push smth else
  - new instruction: Arg(Spur), which pushes a spur to the stack
  - application pops n var names and then n vars
Proj(x): pop v, push p.v
Filter(x): pop 2
- only retain elems in vector that match filter.
- push result back onto stack
Assign(x, bool): pop v, assign/bind x = v in env
- how do we handle binds? answer:
  - don't actually pop v off stack!
  - on assign(x, true), get top v
  - somehow do jumps and all that
  - instead, a bind is two instructions:
    - Push index 0 to stack
    - access and incr
  - add new instruction: conditional jump
    - Jump(ip, =arr_len=)
    - if top of stack < arr len, incr and jump back?
    - this is a do while loop
- for each value in popped v:
  - execute until end
  - go (jump) back to assign, set value to next item in list.
  - or, if we have a "code" stack along with our data stack, we could push a "goto ix" to the code stack, and at the end of executing program, pop first elem off code stack, and go there (if not and end of array)
  - or somehow integrate this with a regular map?
Probably should have other control instructions: jump and return

the stack machine approach could be better for performance and cache locality and all that:
https://news.ycombinator.com/item?id=18822369
https://www.reddit.com/r/learnprogramming/comments/w6i0p/bytecode_execution_vs_ast_walking_speed/c5ax1dw/

stack machine instructions: max 16 bytes. 4 bytes per L1 cache

somehow - connection between this and state machines?

this lets us just execute all instructions of a top-level program in a row.
* stack machine concept in-depth
right now, when executing, we basically use this AST walker lookin thing. it's okay, but it's really unperformant. instead, we should translate our Expressions, we should translate them into what are basically stack VM operations which will be much more simple to evaluate. instead of keeping track of an instruction pointer into program expressions along with dealing with nested recursive function calls and all that, each =ExecEnv= will just have a single instruction pointer. it starts at the beginning of the program, and stops at either an error (returning =None=) or when it sees a =Return= instruction (returns the value and cost). This will need changes to a few parts of the system atm:
** the state ExecEnv needs to store
=ExecEnv= should have two stacks: a =data= stack with =Value= values on it, and a =call= stack which will be explained below.
=ExecEnv= should also keep track of cost as we go along.
And finally, =ExecEnv= should have a few "registers" which will also be explained below:
- =tip=: the index of the top of the branch after the last successful loop iteration.
** how expressions themselves are translated
expressions should be translated as follows:
- =VarExpr(v)= becomes =Var(v)=. Reads =v= from env and pushes it to stack.
- =Proj(v, f)= becomes =Proj(f)=. Pops =v= off stack and projects =f= into it. Pushes result back onto stack.
- =App(e, args)= becomes =Arg(name)= and =App(n)=. =Arg(name)= pushes an argument name to the stack. =App(n)= pops off the last =n * 2= values: the last =n= values are used as the argument names, while the next =n= values are used as the argument values.
- =Filter(o, f, v)= becomes =Filter(f)=. Pops =o= and =v= off the stack. Projects =f= into =o=, then errors out if value isn't equal to =v=.
  - Can be broken down into =Proj(o, f)= and =Guard(v)=; =Guard(v)= pops item off stack and errors out if not equal.
- =Assign(x, v, false)= becomes =Assign(x)=. Pops =v= off stack, assigns it to =x= in env.
- =Assign(x, v, true)= becomes =Bind(x)=. =Bind(x)= first pops =x= off the stack. If =x= is empty, error out. Otherwise, add a tuple with four values to the top of the call stack: the index of =x= on the stack, the ip of the next instruction, 0 (the starting loop index), and the length of the list
- =Ret= is a new instruction that indicates the end of a program. Its behavior changes depending on the contents of the call stack.
  - If the call stack is empty, pop the top value off the stack and return it along with the cost.
  - If the call stack is not empty:
    - Peek at the top of the call stack and increment the third element of the tuple.
    - If the third and fourth elements are not equal, jump back to the ip value given by the second element of the tuple. Set =tip= to the index of the current top of the stack.
    - Otherwise, if the third and fourth elements are equal, we've reached the end of the list. Pop the tuple off the call stack. Pop all elements from the top element of the stack until 1 plus the first element of the tuple (which denotes the stack index of the og list), inserting them into a new array =v=. Then pop the og list off the stack and push =v= to the stack.
      - If =v= is empty, don't bother pushing it to the stack and error out.
      - Otherwise, check the call stack again to see if it's empty (i.e. repeat the logic of =Ret=)
      - In either case, set =tip= to the index of the current top of the stack
*** error behavior
If the stack machine needs to "error out," just pretend like you hit a =Ret= instruction, with the following caveats:

- If the call stack is empty, give up now and return =None=
- Otherwise, do the call stack jumping stuff as dictated by =Ret= semantics above, unsetting the error flag while also removing everything on the stack up until (but not including =tip=)
** create a new state struct for instruction translation
Instead of having disparate functions =translate_expr=, =translate_prog=, etc., they should all be methods of a struct in charge of translation that keeps state: =Compiler= or something. since we now need to be able to keep track of state to have instructions reference other instructions added after itself, we can use the =Compiler= struct to store this state.
* TODO another optimization: cache program size?
